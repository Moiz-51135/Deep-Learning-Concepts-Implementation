{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":482,"sourceType":"datasetVersion","datasetId":228}],"dockerImageVersionId":30626,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-01-10T13:13:06.036961Z","iopub.execute_input":"2024-01-10T13:13:06.037448Z","iopub.status.idle":"2024-01-10T13:13:06.662552Z","shell.execute_reply.started":"2024-01-10T13:13:06.037409Z","shell.execute_reply":"2024-01-10T13:13:06.661563Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"path='/kaggle/input/pima-indians-diabetes-database/diabetes.csv'\ndf=pd.read_csv(path)","metadata":{"execution":{"iopub.status.busy":"2024-01-10T13:13:10.661150Z","iopub.execute_input":"2024-01-10T13:13:10.661728Z","iopub.status.idle":"2024-01-10T13:13:10.692870Z","shell.execute_reply.started":"2024-01-10T13:13:10.661693Z","shell.execute_reply":"2024-01-10T13:13:10.691922Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2024-01-10T13:13:12.397567Z","iopub.execute_input":"2024-01-10T13:13:12.398066Z","iopub.status.idle":"2024-01-10T13:13:12.431663Z","shell.execute_reply.started":"2024-01-10T13:13:12.398016Z","shell.execute_reply":"2024-01-10T13:13:12.430473Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n0            6      148             72             35        0  33.6   \n1            1       85             66             29        0  26.6   \n2            8      183             64              0        0  23.3   \n3            1       89             66             23       94  28.1   \n4            0      137             40             35      168  43.1   \n\n   DiabetesPedigreeFunction  Age  Outcome  \n0                     0.627   50        1  \n1                     0.351   31        0  \n2                     0.672   32        1  \n3                     0.167   21        0  \n4                     2.288   33        1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Pregnancies</th>\n      <th>Glucose</th>\n      <th>BloodPressure</th>\n      <th>SkinThickness</th>\n      <th>Insulin</th>\n      <th>BMI</th>\n      <th>DiabetesPedigreeFunction</th>\n      <th>Age</th>\n      <th>Outcome</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>6</td>\n      <td>148</td>\n      <td>72</td>\n      <td>35</td>\n      <td>0</td>\n      <td>33.6</td>\n      <td>0.627</td>\n      <td>50</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>85</td>\n      <td>66</td>\n      <td>29</td>\n      <td>0</td>\n      <td>26.6</td>\n      <td>0.351</td>\n      <td>31</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8</td>\n      <td>183</td>\n      <td>64</td>\n      <td>0</td>\n      <td>0</td>\n      <td>23.3</td>\n      <td>0.672</td>\n      <td>32</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>89</td>\n      <td>66</td>\n      <td>23</td>\n      <td>94</td>\n      <td>28.1</td>\n      <td>0.167</td>\n      <td>21</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>137</td>\n      <td>40</td>\n      <td>35</td>\n      <td>168</td>\n      <td>43.1</td>\n      <td>2.288</td>\n      <td>33</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2024-01-10T13:13:13.604949Z","iopub.execute_input":"2024-01-10T13:13:13.605762Z","iopub.status.idle":"2024-01-10T13:13:13.615318Z","shell.execute_reply.started":"2024-01-10T13:13:13.605712Z","shell.execute_reply":"2024-01-10T13:13:13.613755Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"(768, 9)"},"metadata":{}}]},{"cell_type":"code","source":"df.duplicated().sum()","metadata":{"execution":{"iopub.status.busy":"2024-01-10T13:13:30.144294Z","iopub.execute_input":"2024-01-10T13:13:30.144753Z","iopub.status.idle":"2024-01-10T13:13:30.156116Z","shell.execute_reply.started":"2024-01-10T13:13:30.144720Z","shell.execute_reply":"2024-01-10T13:13:30.154644Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"code","source":"df.corr()['Outcome']","metadata":{"execution":{"iopub.status.busy":"2024-01-10T13:13:31.072824Z","iopub.execute_input":"2024-01-10T13:13:31.073268Z","iopub.status.idle":"2024-01-10T13:13:31.083877Z","shell.execute_reply.started":"2024-01-10T13:13:31.073237Z","shell.execute_reply":"2024-01-10T13:13:31.082504Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"Pregnancies                 0.221898\nGlucose                     0.466581\nBloodPressure               0.065068\nSkinThickness               0.074752\nInsulin                     0.130548\nBMI                         0.292695\nDiabetesPedigreeFunction    0.173844\nAge                         0.238356\nOutcome                     1.000000\nName: Outcome, dtype: float64"},"metadata":{}}]},{"cell_type":"code","source":"X = df[['Pregnancies', 'Glucose', 'Insulin', 'BMI', 'Age', 'DiabetesPedigreeFunction']]\ny = df['Outcome']\nprint(\"X (features):\")\nprint(X)\n\nprint(\"\\ny (target):\")\nprint(y)","metadata":{"execution":{"iopub.status.busy":"2024-01-10T13:13:32.576858Z","iopub.execute_input":"2024-01-10T13:13:32.577647Z","iopub.status.idle":"2024-01-10T13:13:32.596020Z","shell.execute_reply.started":"2024-01-10T13:13:32.577610Z","shell.execute_reply":"2024-01-10T13:13:32.594912Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"X (features):\n     Pregnancies  Glucose  Insulin   BMI  Age  DiabetesPedigreeFunction\n0              6      148        0  33.6   50                     0.627\n1              1       85        0  26.6   31                     0.351\n2              8      183        0  23.3   32                     0.672\n3              1       89       94  28.1   21                     0.167\n4              0      137      168  43.1   33                     2.288\n..           ...      ...      ...   ...  ...                       ...\n763           10      101      180  32.9   63                     0.171\n764            2      122        0  36.8   27                     0.340\n765            5      121      112  26.2   30                     0.245\n766            1      126        0  30.1   47                     0.349\n767            1       93        0  30.4   23                     0.315\n\n[768 rows x 6 columns]\n\ny (target):\n0      1\n1      0\n2      1\n3      0\n4      1\n      ..\n763    0\n764    0\n765    0\n766    1\n767    0\nName: Outcome, Length: 768, dtype: int64\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler","metadata":{"execution":{"iopub.status.busy":"2024-01-10T13:13:36.500198Z","iopub.execute_input":"2024-01-10T13:13:36.501342Z","iopub.status.idle":"2024-01-10T13:13:36.507668Z","shell.execute_reply.started":"2024-01-10T13:13:36.501284Z","shell.execute_reply":"2024-01-10T13:13:36.506123Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"scaler = StandardScaler()","metadata":{"execution":{"iopub.status.busy":"2024-01-10T13:14:14.147500Z","iopub.execute_input":"2024-01-10T13:14:14.148673Z","iopub.status.idle":"2024-01-10T13:14:14.154411Z","shell.execute_reply.started":"2024-01-10T13:14:14.148618Z","shell.execute_reply":"2024-01-10T13:14:14.153308Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"X= scaler.fit_transform(X)","metadata":{"execution":{"iopub.status.busy":"2024-01-10T13:14:57.424174Z","iopub.execute_input":"2024-01-10T13:14:57.425854Z","iopub.status.idle":"2024-01-10T13:14:57.437355Z","shell.execute_reply.started":"2024-01-10T13:14:57.425799Z","shell.execute_reply":"2024-01-10T13:14:57.435402Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"X.shape","metadata":{"execution":{"iopub.status.busy":"2024-01-10T13:15:11.127196Z","iopub.execute_input":"2024-01-10T13:15:11.128221Z","iopub.status.idle":"2024-01-10T13:15:11.139831Z","shell.execute_reply.started":"2024-01-10T13:15:11.128170Z","shell.execute_reply":"2024-01-10T13:15:11.137989Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"(768, 6)"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=1)","metadata":{"execution":{"iopub.status.busy":"2024-01-10T13:17:24.859301Z","iopub.execute_input":"2024-01-10T13:17:24.859782Z","iopub.status.idle":"2024-01-10T13:17:24.977962Z","shell.execute_reply.started":"2024-01-10T13:17:24.859749Z","shell.execute_reply":"2024-01-10T13:17:24.976763Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"import tensorflow\nfrom tensorflow import keras\nfrom keras import Sequential\nfrom keras.layers import Dense","metadata":{"execution":{"iopub.status.busy":"2024-01-10T13:19:30.235955Z","iopub.execute_input":"2024-01-10T13:19:30.236901Z","iopub.status.idle":"2024-01-10T13:19:30.244622Z","shell.execute_reply.started":"2024-01-10T13:19:30.236842Z","shell.execute_reply":"2024-01-10T13:19:30.242997Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"model= Sequential()\nmodel.add(Dense(32,activation='relu',input_dim=6))\nmodel.add(Dense(1,activation='sigmoid'))","metadata":{"execution":{"iopub.status.busy":"2024-01-10T13:21:02.278814Z","iopub.execute_input":"2024-01-10T13:21:02.279285Z","iopub.status.idle":"2024-01-10T13:21:02.474580Z","shell.execute_reply.started":"2024-01-10T13:21:02.279243Z","shell.execute_reply":"2024-01-10T13:21:02.473224Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2024-01-10T13:21:09.633105Z","iopub.execute_input":"2024-01-10T13:21:09.633542Z","iopub.status.idle":"2024-01-10T13:21:09.653680Z","shell.execute_reply.started":"2024-01-10T13:21:09.633500Z","shell.execute_reply":"2024-01-10T13:21:09.652735Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n dense (Dense)               (None, 32)                224       \n                                                                 \n dense_1 (Dense)             (None, 1)                 33        \n                                                                 \n=================================================================\nTotal params: 257 (1.00 KB)\nTrainable params: 257 (1.00 KB)\nNon-trainable params: 0 (0.00 Byte)\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"model.compile(optimizer='Adam',loss='binary_crossentropy',metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2024-01-10T13:22:09.100177Z","iopub.execute_input":"2024-01-10T13:22:09.100617Z","iopub.status.idle":"2024-01-10T13:22:09.121937Z","shell.execute_reply.started":"2024-01-10T13:22:09.100581Z","shell.execute_reply":"2024-01-10T13:22:09.120638Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"model.fit(X_train,y_train,batch_size=32,epochs=100,validation_data=(X_test,y_test))","metadata":{"execution":{"iopub.status.busy":"2024-01-10T13:23:29.670885Z","iopub.execute_input":"2024-01-10T13:23:29.672579Z","iopub.status.idle":"2024-01-10T13:23:39.655905Z","shell.execute_reply.started":"2024-01-10T13:23:29.672521Z","shell.execute_reply":"2024-01-10T13:23:39.654472Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Epoch 1/100\n20/20 [==============================] - 0s 7ms/step - loss: 0.4878 - accuracy: 0.7622 - val_loss: 0.4763 - val_accuracy: 0.7987\nEpoch 2/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4833 - accuracy: 0.7671 - val_loss: 0.4710 - val_accuracy: 0.8052\nEpoch 3/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.4794 - accuracy: 0.7736 - val_loss: 0.4682 - val_accuracy: 0.8052\nEpoch 4/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4760 - accuracy: 0.7704 - val_loss: 0.4663 - val_accuracy: 0.8052\nEpoch 5/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.4730 - accuracy: 0.7671 - val_loss: 0.4645 - val_accuracy: 0.7987\nEpoch 6/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.4705 - accuracy: 0.7687 - val_loss: 0.4608 - val_accuracy: 0.8052\nEpoch 7/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.4686 - accuracy: 0.7638 - val_loss: 0.4599 - val_accuracy: 0.7987\nEpoch 8/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.4665 - accuracy: 0.7638 - val_loss: 0.4586 - val_accuracy: 0.8052\nEpoch 9/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.4652 - accuracy: 0.7687 - val_loss: 0.4598 - val_accuracy: 0.7987\nEpoch 10/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4633 - accuracy: 0.7720 - val_loss: 0.4590 - val_accuracy: 0.8052\nEpoch 11/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.4619 - accuracy: 0.7704 - val_loss: 0.4584 - val_accuracy: 0.7987\nEpoch 12/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4607 - accuracy: 0.7736 - val_loss: 0.4580 - val_accuracy: 0.7987\nEpoch 13/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.4602 - accuracy: 0.7704 - val_loss: 0.4580 - val_accuracy: 0.7987\nEpoch 14/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.4596 - accuracy: 0.7736 - val_loss: 0.4583 - val_accuracy: 0.7987\nEpoch 15/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.4580 - accuracy: 0.7720 - val_loss: 0.4581 - val_accuracy: 0.7987\nEpoch 16/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.4571 - accuracy: 0.7736 - val_loss: 0.4571 - val_accuracy: 0.7987\nEpoch 17/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.4567 - accuracy: 0.7752 - val_loss: 0.4565 - val_accuracy: 0.7987\nEpoch 18/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.4561 - accuracy: 0.7769 - val_loss: 0.4579 - val_accuracy: 0.8052\nEpoch 19/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4552 - accuracy: 0.7752 - val_loss: 0.4575 - val_accuracy: 0.8052\nEpoch 20/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.4542 - accuracy: 0.7769 - val_loss: 0.4579 - val_accuracy: 0.8052\nEpoch 21/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.4538 - accuracy: 0.7785 - val_loss: 0.4577 - val_accuracy: 0.8052\nEpoch 22/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.4533 - accuracy: 0.7785 - val_loss: 0.4565 - val_accuracy: 0.8052\nEpoch 23/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.4531 - accuracy: 0.7785 - val_loss: 0.4571 - val_accuracy: 0.8117\nEpoch 24/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4522 - accuracy: 0.7769 - val_loss: 0.4587 - val_accuracy: 0.8052\nEpoch 25/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.4522 - accuracy: 0.7752 - val_loss: 0.4572 - val_accuracy: 0.8052\nEpoch 26/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.4521 - accuracy: 0.7785 - val_loss: 0.4573 - val_accuracy: 0.8117\nEpoch 27/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.4509 - accuracy: 0.7736 - val_loss: 0.4576 - val_accuracy: 0.8052\nEpoch 28/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.4514 - accuracy: 0.7752 - val_loss: 0.4590 - val_accuracy: 0.8052\nEpoch 29/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.4513 - accuracy: 0.7769 - val_loss: 0.4598 - val_accuracy: 0.8052\nEpoch 30/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4501 - accuracy: 0.7752 - val_loss: 0.4592 - val_accuracy: 0.8052\nEpoch 31/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.4497 - accuracy: 0.7769 - val_loss: 0.4595 - val_accuracy: 0.8052\nEpoch 32/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4489 - accuracy: 0.7769 - val_loss: 0.4599 - val_accuracy: 0.8052\nEpoch 33/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4489 - accuracy: 0.7769 - val_loss: 0.4599 - val_accuracy: 0.8117\nEpoch 34/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4482 - accuracy: 0.7769 - val_loss: 0.4603 - val_accuracy: 0.8117\nEpoch 35/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.4478 - accuracy: 0.7769 - val_loss: 0.4600 - val_accuracy: 0.8117\nEpoch 36/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.4478 - accuracy: 0.7752 - val_loss: 0.4595 - val_accuracy: 0.8117\nEpoch 37/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.4476 - accuracy: 0.7752 - val_loss: 0.4590 - val_accuracy: 0.8117\nEpoch 38/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4469 - accuracy: 0.7769 - val_loss: 0.4604 - val_accuracy: 0.8117\nEpoch 39/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.4469 - accuracy: 0.7801 - val_loss: 0.4600 - val_accuracy: 0.8117\nEpoch 40/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.4467 - accuracy: 0.7769 - val_loss: 0.4609 - val_accuracy: 0.8117\nEpoch 41/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.4464 - accuracy: 0.7769 - val_loss: 0.4610 - val_accuracy: 0.8117\nEpoch 42/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.4457 - accuracy: 0.7785 - val_loss: 0.4612 - val_accuracy: 0.8117\nEpoch 43/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4454 - accuracy: 0.7801 - val_loss: 0.4609 - val_accuracy: 0.8117\nEpoch 44/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4450 - accuracy: 0.7801 - val_loss: 0.4608 - val_accuracy: 0.8117\nEpoch 45/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.4445 - accuracy: 0.7769 - val_loss: 0.4601 - val_accuracy: 0.8117\nEpoch 46/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.4445 - accuracy: 0.7752 - val_loss: 0.4594 - val_accuracy: 0.8117\nEpoch 47/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.4443 - accuracy: 0.7785 - val_loss: 0.4600 - val_accuracy: 0.8117\nEpoch 48/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.4437 - accuracy: 0.7801 - val_loss: 0.4598 - val_accuracy: 0.8117\nEpoch 49/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.4435 - accuracy: 0.7850 - val_loss: 0.4593 - val_accuracy: 0.8117\nEpoch 50/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.4433 - accuracy: 0.7834 - val_loss: 0.4594 - val_accuracy: 0.8117\nEpoch 51/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.4429 - accuracy: 0.7818 - val_loss: 0.4608 - val_accuracy: 0.8117\nEpoch 52/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.4427 - accuracy: 0.7850 - val_loss: 0.4617 - val_accuracy: 0.8117\nEpoch 53/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.4430 - accuracy: 0.7850 - val_loss: 0.4632 - val_accuracy: 0.8117\nEpoch 54/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.4424 - accuracy: 0.7850 - val_loss: 0.4637 - val_accuracy: 0.8117\nEpoch 55/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.4420 - accuracy: 0.7866 - val_loss: 0.4636 - val_accuracy: 0.8117\nEpoch 56/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.4416 - accuracy: 0.7883 - val_loss: 0.4630 - val_accuracy: 0.8117\nEpoch 57/100\n20/20 [==============================] - 0s 6ms/step - loss: 0.4419 - accuracy: 0.7850 - val_loss: 0.4644 - val_accuracy: 0.8117\nEpoch 58/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.4414 - accuracy: 0.7866 - val_loss: 0.4645 - val_accuracy: 0.8117\nEpoch 59/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4408 - accuracy: 0.7818 - val_loss: 0.4644 - val_accuracy: 0.8117\nEpoch 60/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.4407 - accuracy: 0.7818 - val_loss: 0.4644 - val_accuracy: 0.8117\nEpoch 61/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.4406 - accuracy: 0.7834 - val_loss: 0.4638 - val_accuracy: 0.8117\nEpoch 62/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.4404 - accuracy: 0.7818 - val_loss: 0.4641 - val_accuracy: 0.8117\nEpoch 63/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4403 - accuracy: 0.7834 - val_loss: 0.4644 - val_accuracy: 0.8117\nEpoch 64/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4405 - accuracy: 0.7834 - val_loss: 0.4664 - val_accuracy: 0.8117\nEpoch 65/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.4394 - accuracy: 0.7818 - val_loss: 0.4638 - val_accuracy: 0.8117\nEpoch 66/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4394 - accuracy: 0.7866 - val_loss: 0.4633 - val_accuracy: 0.8117\nEpoch 67/100\n20/20 [==============================] - 0s 7ms/step - loss: 0.4394 - accuracy: 0.7850 - val_loss: 0.4626 - val_accuracy: 0.8117\nEpoch 68/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.4391 - accuracy: 0.7883 - val_loss: 0.4627 - val_accuracy: 0.8117\nEpoch 69/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4391 - accuracy: 0.7850 - val_loss: 0.4623 - val_accuracy: 0.8117\nEpoch 70/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.4388 - accuracy: 0.7785 - val_loss: 0.4639 - val_accuracy: 0.8117\nEpoch 71/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4383 - accuracy: 0.7866 - val_loss: 0.4628 - val_accuracy: 0.8117\nEpoch 72/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4381 - accuracy: 0.7883 - val_loss: 0.4636 - val_accuracy: 0.8117\nEpoch 73/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4383 - accuracy: 0.7883 - val_loss: 0.4621 - val_accuracy: 0.8117\nEpoch 74/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4382 - accuracy: 0.7850 - val_loss: 0.4636 - val_accuracy: 0.8117\nEpoch 75/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.4381 - accuracy: 0.7834 - val_loss: 0.4648 - val_accuracy: 0.8052\nEpoch 76/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.4371 - accuracy: 0.7899 - val_loss: 0.4638 - val_accuracy: 0.8117\nEpoch 77/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.4371 - accuracy: 0.7866 - val_loss: 0.4651 - val_accuracy: 0.8117\nEpoch 78/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4374 - accuracy: 0.7850 - val_loss: 0.4646 - val_accuracy: 0.8117\nEpoch 79/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.4371 - accuracy: 0.7883 - val_loss: 0.4635 - val_accuracy: 0.8117\nEpoch 80/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.4366 - accuracy: 0.7883 - val_loss: 0.4646 - val_accuracy: 0.8117\nEpoch 81/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.4359 - accuracy: 0.7899 - val_loss: 0.4659 - val_accuracy: 0.8117\nEpoch 82/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4365 - accuracy: 0.7866 - val_loss: 0.4638 - val_accuracy: 0.8117\nEpoch 83/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4358 - accuracy: 0.7899 - val_loss: 0.4634 - val_accuracy: 0.8117\nEpoch 84/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4360 - accuracy: 0.7899 - val_loss: 0.4631 - val_accuracy: 0.8117\nEpoch 85/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4358 - accuracy: 0.7932 - val_loss: 0.4649 - val_accuracy: 0.8117\nEpoch 86/100\n20/20 [==============================] - 0s 6ms/step - loss: 0.4351 - accuracy: 0.7899 - val_loss: 0.4657 - val_accuracy: 0.8117\nEpoch 87/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.4355 - accuracy: 0.7883 - val_loss: 0.4659 - val_accuracy: 0.8117\nEpoch 88/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.4351 - accuracy: 0.7932 - val_loss: 0.4639 - val_accuracy: 0.8117\nEpoch 89/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4348 - accuracy: 0.7866 - val_loss: 0.4640 - val_accuracy: 0.8117\nEpoch 90/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.4345 - accuracy: 0.7899 - val_loss: 0.4655 - val_accuracy: 0.8117\nEpoch 91/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.4345 - accuracy: 0.7932 - val_loss: 0.4658 - val_accuracy: 0.8117\nEpoch 92/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4342 - accuracy: 0.7948 - val_loss: 0.4657 - val_accuracy: 0.8117\nEpoch 93/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4347 - accuracy: 0.7948 - val_loss: 0.4670 - val_accuracy: 0.8117\nEpoch 94/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.4336 - accuracy: 0.7915 - val_loss: 0.4663 - val_accuracy: 0.8117\nEpoch 95/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4332 - accuracy: 0.7915 - val_loss: 0.4663 - val_accuracy: 0.8182\nEpoch 96/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.4329 - accuracy: 0.7964 - val_loss: 0.4657 - val_accuracy: 0.8182\nEpoch 97/100\n20/20 [==============================] - 0s 6ms/step - loss: 0.4331 - accuracy: 0.7899 - val_loss: 0.4660 - val_accuracy: 0.8182\nEpoch 98/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.4329 - accuracy: 0.7980 - val_loss: 0.4661 - val_accuracy: 0.8052\nEpoch 99/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.4325 - accuracy: 0.7964 - val_loss: 0.4663 - val_accuracy: 0.8117\nEpoch 100/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4327 - accuracy: 0.7948 - val_loss: 0.4671 - val_accuracy: 0.8182\n","output_type":"stream"},{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.History at 0x7b14006b5600>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Finding best optimizer using Keras-Tuner","metadata":{}},{"cell_type":"code","source":"pip install -U keras-tuner","metadata":{"execution":{"iopub.status.busy":"2024-01-10T13:26:20.914161Z","iopub.execute_input":"2024-01-10T13:26:20.915659Z","iopub.status.idle":"2024-01-10T13:26:36.333504Z","shell.execute_reply.started":"2024-01-10T13:26:20.915590Z","shell.execute_reply":"2024-01-10T13:26:36.331912Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Requirement already satisfied: keras-tuner in /opt/conda/lib/python3.10/site-packages (1.3.5)\nCollecting keras-tuner\n  Obtaining dependency information for keras-tuner from https://files.pythonhosted.org/packages/2b/39/21f819fcda657c37519cf817ca1cd03a8a025262aad360876d2a971d38b3/keras_tuner-1.4.6-py3-none-any.whl.metadata\n  Downloading keras_tuner-1.4.6-py3-none-any.whl.metadata (5.4 kB)\nRequirement already satisfied: keras in /opt/conda/lib/python3.10/site-packages (from keras-tuner) (2.13.1)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from keras-tuner) (21.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from keras-tuner) (2.31.0)\nRequirement already satisfied: kt-legacy in /opt/conda/lib/python3.10/site-packages (from keras-tuner) (1.0.5)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->keras-tuner) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->keras-tuner) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->keras-tuner) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->keras-tuner) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->keras-tuner) (2023.11.17)\nDownloading keras_tuner-1.4.6-py3-none-any.whl (128 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.9/128.9 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: keras-tuner\n  Attempting uninstall: keras-tuner\n    Found existing installation: keras-tuner 1.3.5\n    Uninstalling keras-tuner-1.3.5:\n      Successfully uninstalled keras-tuner-1.3.5\nSuccessfully installed keras-tuner-1.4.6\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import keras_tuner as kt","metadata":{"execution":{"iopub.status.busy":"2024-01-10T13:44:36.452630Z","iopub.execute_input":"2024-01-10T13:44:36.453112Z","iopub.status.idle":"2024-01-10T13:44:36.458712Z","shell.execute_reply.started":"2024-01-10T13:44:36.453075Z","shell.execute_reply":"2024-01-10T13:44:36.457786Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"import keras_tuner as kt\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_model(hp):\n    model = Sequential()\n    model.add(Dense(32, activation='relu', input_dim=6))\n    model.add(Dense(1, activation='sigmoid'))\n\n    optimizer = hp.Choice('optimizer', values=['adam', 'sgd', 'rmsprop', 'adadelta'])\n    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2024-01-10T13:47:05.508816Z","iopub.execute_input":"2024-01-10T13:47:05.509279Z","iopub.status.idle":"2024-01-10T13:47:05.522009Z","shell.execute_reply.started":"2024-01-10T13:47:05.509247Z","shell.execute_reply":"2024-01-10T13:47:05.520432Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"tuner = kt.RandomSearch(build_model, objective='val_accuracy', max_trials=5)","metadata":{"execution":{"iopub.status.busy":"2024-01-10T13:48:01.355153Z","iopub.execute_input":"2024-01-10T13:48:01.356139Z","iopub.status.idle":"2024-01-10T13:48:01.368453Z","shell.execute_reply.started":"2024-01-10T13:48:01.356085Z","shell.execute_reply":"2024-01-10T13:48:01.367507Z"},"trusted":true},"execution_count":53,"outputs":[{"name":"stdout","text":"Reloading Tuner from ./untitled_project/tuner0.json\n","output_type":"stream"}]},{"cell_type":"code","source":"tuner.search(X_train,y_train,epochs=30,validation_data=(X_test,y_test))","metadata":{"execution":{"iopub.status.busy":"2024-01-10T13:48:04.361807Z","iopub.execute_input":"2024-01-10T13:48:04.362808Z","iopub.status.idle":"2024-01-10T13:48:04.370309Z","shell.execute_reply.started":"2024-01-10T13:48:04.362760Z","shell.execute_reply":"2024-01-10T13:48:04.369512Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"tuner.get_best_hyperparameters()[0].values","metadata":{"execution":{"iopub.status.busy":"2024-01-10T13:49:22.470517Z","iopub.execute_input":"2024-01-10T13:49:22.471000Z","iopub.status.idle":"2024-01-10T13:49:22.480129Z","shell.execute_reply.started":"2024-01-10T13:49:22.470961Z","shell.execute_reply":"2024-01-10T13:49:22.478784Z"},"trusted":true},"execution_count":56,"outputs":[{"execution_count":56,"output_type":"execute_result","data":{"text/plain":"{'optimizer': 'rmsprop'}"},"metadata":{}}]},{"cell_type":"code","source":"model = tuner.get_best_models(num_models=1)[0]","metadata":{"execution":{"iopub.status.busy":"2024-01-10T13:51:03.320943Z","iopub.execute_input":"2024-01-10T13:51:03.321442Z","iopub.status.idle":"2024-01-10T13:51:04.114396Z","shell.execute_reply.started":"2024-01-10T13:51:03.321398Z","shell.execute_reply":"2024-01-10T13:51:04.113115Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2024-01-10T13:51:09.808062Z","iopub.execute_input":"2024-01-10T13:51:09.808581Z","iopub.status.idle":"2024-01-10T13:51:09.829604Z","shell.execute_reply.started":"2024-01-10T13:51:09.808544Z","shell.execute_reply":"2024-01-10T13:51:09.828452Z"},"trusted":true},"execution_count":58,"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n dense (Dense)               (None, 32)                224       \n                                                                 \n dense_1 (Dense)             (None, 1)                 33        \n                                                                 \n=================================================================\nTotal params: 257 (1.00 KB)\nTrainable params: 257 (1.00 KB)\nNon-trainable params: 0 (0.00 Byte)\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"model.fit(X_train,y_train,batch_size=32,epochs=100,initial_epoch=6,validation_data=(X_test,y_test))","metadata":{"execution":{"iopub.status.busy":"2024-01-10T13:53:22.154935Z","iopub.execute_input":"2024-01-10T13:53:22.155422Z","iopub.status.idle":"2024-01-10T13:53:30.740168Z","shell.execute_reply.started":"2024-01-10T13:53:22.155370Z","shell.execute_reply":"2024-01-10T13:53:30.739071Z"},"trusted":true},"execution_count":61,"outputs":[{"name":"stdout","text":"Epoch 7/100\n20/20 [==============================] - 1s 13ms/step - loss: 0.5099 - accuracy: 0.7704 - val_loss: 0.5069 - val_accuracy: 0.7727\nEpoch 8/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4987 - accuracy: 0.7769 - val_loss: 0.4981 - val_accuracy: 0.7727\nEpoch 9/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4904 - accuracy: 0.7752 - val_loss: 0.4912 - val_accuracy: 0.7727\nEpoch 10/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4841 - accuracy: 0.7736 - val_loss: 0.4873 - val_accuracy: 0.7662\nEpoch 11/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4801 - accuracy: 0.7720 - val_loss: 0.4844 - val_accuracy: 0.7662\nEpoch 12/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4766 - accuracy: 0.7736 - val_loss: 0.4823 - val_accuracy: 0.7662\nEpoch 13/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.4733 - accuracy: 0.7736 - val_loss: 0.4802 - val_accuracy: 0.7662\nEpoch 14/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4713 - accuracy: 0.7720 - val_loss: 0.4776 - val_accuracy: 0.7662\nEpoch 15/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4690 - accuracy: 0.7720 - val_loss: 0.4756 - val_accuracy: 0.7792\nEpoch 16/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4673 - accuracy: 0.7720 - val_loss: 0.4747 - val_accuracy: 0.7662\nEpoch 17/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4654 - accuracy: 0.7769 - val_loss: 0.4740 - val_accuracy: 0.7662\nEpoch 18/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4641 - accuracy: 0.7785 - val_loss: 0.4734 - val_accuracy: 0.7662\nEpoch 19/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4630 - accuracy: 0.7769 - val_loss: 0.4727 - val_accuracy: 0.7662\nEpoch 20/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4618 - accuracy: 0.7736 - val_loss: 0.4730 - val_accuracy: 0.7662\nEpoch 21/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4612 - accuracy: 0.7704 - val_loss: 0.4722 - val_accuracy: 0.7662\nEpoch 22/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4603 - accuracy: 0.7736 - val_loss: 0.4720 - val_accuracy: 0.7662\nEpoch 23/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4596 - accuracy: 0.7736 - val_loss: 0.4709 - val_accuracy: 0.7857\nEpoch 24/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4588 - accuracy: 0.7736 - val_loss: 0.4711 - val_accuracy: 0.7922\nEpoch 25/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4582 - accuracy: 0.7769 - val_loss: 0.4717 - val_accuracy: 0.7987\nEpoch 26/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4573 - accuracy: 0.7720 - val_loss: 0.4709 - val_accuracy: 0.7857\nEpoch 27/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4564 - accuracy: 0.7704 - val_loss: 0.4702 - val_accuracy: 0.7922\nEpoch 28/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4566 - accuracy: 0.7736 - val_loss: 0.4703 - val_accuracy: 0.7857\nEpoch 29/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4556 - accuracy: 0.7752 - val_loss: 0.4708 - val_accuracy: 0.7857\nEpoch 30/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4550 - accuracy: 0.7785 - val_loss: 0.4710 - val_accuracy: 0.7857\nEpoch 31/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4545 - accuracy: 0.7752 - val_loss: 0.4707 - val_accuracy: 0.7922\nEpoch 32/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4540 - accuracy: 0.7769 - val_loss: 0.4704 - val_accuracy: 0.7922\nEpoch 33/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4537 - accuracy: 0.7769 - val_loss: 0.4700 - val_accuracy: 0.8052\nEpoch 34/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4531 - accuracy: 0.7752 - val_loss: 0.4693 - val_accuracy: 0.7987\nEpoch 35/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4527 - accuracy: 0.7785 - val_loss: 0.4695 - val_accuracy: 0.7922\nEpoch 36/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4523 - accuracy: 0.7785 - val_loss: 0.4693 - val_accuracy: 0.7987\nEpoch 37/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4518 - accuracy: 0.7801 - val_loss: 0.4693 - val_accuracy: 0.7987\nEpoch 38/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4514 - accuracy: 0.7769 - val_loss: 0.4700 - val_accuracy: 0.7987\nEpoch 39/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4512 - accuracy: 0.7785 - val_loss: 0.4698 - val_accuracy: 0.8052\nEpoch 40/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.4508 - accuracy: 0.7801 - val_loss: 0.4701 - val_accuracy: 0.8052\nEpoch 41/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4500 - accuracy: 0.7801 - val_loss: 0.4700 - val_accuracy: 0.8052\nEpoch 42/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4499 - accuracy: 0.7769 - val_loss: 0.4709 - val_accuracy: 0.7987\nEpoch 43/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4496 - accuracy: 0.7785 - val_loss: 0.4701 - val_accuracy: 0.8052\nEpoch 44/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4492 - accuracy: 0.7785 - val_loss: 0.4699 - val_accuracy: 0.8052\nEpoch 45/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4488 - accuracy: 0.7801 - val_loss: 0.4689 - val_accuracy: 0.8052\nEpoch 46/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4483 - accuracy: 0.7801 - val_loss: 0.4693 - val_accuracy: 0.7987\nEpoch 47/100\n20/20 [==============================] - 0s 6ms/step - loss: 0.4484 - accuracy: 0.7785 - val_loss: 0.4695 - val_accuracy: 0.7987\nEpoch 48/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4479 - accuracy: 0.7785 - val_loss: 0.4698 - val_accuracy: 0.7987\nEpoch 49/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4476 - accuracy: 0.7818 - val_loss: 0.4687 - val_accuracy: 0.7987\nEpoch 50/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4472 - accuracy: 0.7818 - val_loss: 0.4693 - val_accuracy: 0.7987\nEpoch 51/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4468 - accuracy: 0.7834 - val_loss: 0.4684 - val_accuracy: 0.8052\nEpoch 52/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4464 - accuracy: 0.7801 - val_loss: 0.4682 - val_accuracy: 0.8052\nEpoch 53/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4462 - accuracy: 0.7801 - val_loss: 0.4681 - val_accuracy: 0.8052\nEpoch 54/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4460 - accuracy: 0.7785 - val_loss: 0.4684 - val_accuracy: 0.7987\nEpoch 55/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4454 - accuracy: 0.7769 - val_loss: 0.4684 - val_accuracy: 0.7987\nEpoch 56/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4454 - accuracy: 0.7818 - val_loss: 0.4679 - val_accuracy: 0.8052\nEpoch 57/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4448 - accuracy: 0.7801 - val_loss: 0.4670 - val_accuracy: 0.8052\nEpoch 58/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4442 - accuracy: 0.7801 - val_loss: 0.4678 - val_accuracy: 0.8052\nEpoch 59/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4442 - accuracy: 0.7785 - val_loss: 0.4673 - val_accuracy: 0.8052\nEpoch 60/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4440 - accuracy: 0.7818 - val_loss: 0.4665 - val_accuracy: 0.8052\nEpoch 61/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4438 - accuracy: 0.7801 - val_loss: 0.4676 - val_accuracy: 0.8052\nEpoch 62/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4437 - accuracy: 0.7818 - val_loss: 0.4674 - val_accuracy: 0.8052\nEpoch 63/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4433 - accuracy: 0.7801 - val_loss: 0.4669 - val_accuracy: 0.8052\nEpoch 64/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.4430 - accuracy: 0.7818 - val_loss: 0.4672 - val_accuracy: 0.8052\nEpoch 65/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4424 - accuracy: 0.7801 - val_loss: 0.4675 - val_accuracy: 0.8052\nEpoch 66/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4426 - accuracy: 0.7834 - val_loss: 0.4673 - val_accuracy: 0.8052\nEpoch 67/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.4424 - accuracy: 0.7834 - val_loss: 0.4675 - val_accuracy: 0.8052\nEpoch 68/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4418 - accuracy: 0.7866 - val_loss: 0.4667 - val_accuracy: 0.8052\nEpoch 69/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4420 - accuracy: 0.7834 - val_loss: 0.4667 - val_accuracy: 0.8052\nEpoch 70/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4416 - accuracy: 0.7866 - val_loss: 0.4663 - val_accuracy: 0.8052\nEpoch 71/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4410 - accuracy: 0.7818 - val_loss: 0.4660 - val_accuracy: 0.8052\nEpoch 72/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4409 - accuracy: 0.7818 - val_loss: 0.4654 - val_accuracy: 0.8052\nEpoch 73/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4406 - accuracy: 0.7801 - val_loss: 0.4650 - val_accuracy: 0.8052\nEpoch 74/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4407 - accuracy: 0.7785 - val_loss: 0.4651 - val_accuracy: 0.8052\nEpoch 75/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4402 - accuracy: 0.7801 - val_loss: 0.4648 - val_accuracy: 0.8052\nEpoch 76/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4400 - accuracy: 0.7801 - val_loss: 0.4658 - val_accuracy: 0.8052\nEpoch 77/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4396 - accuracy: 0.7769 - val_loss: 0.4671 - val_accuracy: 0.8052\nEpoch 78/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4392 - accuracy: 0.7801 - val_loss: 0.4675 - val_accuracy: 0.8052\nEpoch 79/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4397 - accuracy: 0.7850 - val_loss: 0.4671 - val_accuracy: 0.8052\nEpoch 80/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4392 - accuracy: 0.7850 - val_loss: 0.4676 - val_accuracy: 0.8052\nEpoch 81/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4389 - accuracy: 0.7834 - val_loss: 0.4674 - val_accuracy: 0.8052\nEpoch 82/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4388 - accuracy: 0.7801 - val_loss: 0.4674 - val_accuracy: 0.8052\nEpoch 83/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4385 - accuracy: 0.7834 - val_loss: 0.4685 - val_accuracy: 0.7987\nEpoch 84/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4384 - accuracy: 0.7801 - val_loss: 0.4689 - val_accuracy: 0.7987\nEpoch 85/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4382 - accuracy: 0.7818 - val_loss: 0.4680 - val_accuracy: 0.8052\nEpoch 86/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4377 - accuracy: 0.7818 - val_loss: 0.4683 - val_accuracy: 0.8052\nEpoch 87/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4377 - accuracy: 0.7883 - val_loss: 0.4678 - val_accuracy: 0.7987\nEpoch 88/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4372 - accuracy: 0.7866 - val_loss: 0.4670 - val_accuracy: 0.8052\nEpoch 89/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4375 - accuracy: 0.7834 - val_loss: 0.4663 - val_accuracy: 0.8052\nEpoch 90/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4369 - accuracy: 0.7801 - val_loss: 0.4666 - val_accuracy: 0.8117\nEpoch 91/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4369 - accuracy: 0.7801 - val_loss: 0.4673 - val_accuracy: 0.8052\nEpoch 92/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4365 - accuracy: 0.7883 - val_loss: 0.4670 - val_accuracy: 0.8052\nEpoch 93/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4363 - accuracy: 0.7834 - val_loss: 0.4668 - val_accuracy: 0.8117\nEpoch 94/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4362 - accuracy: 0.7834 - val_loss: 0.4668 - val_accuracy: 0.8052\nEpoch 95/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4359 - accuracy: 0.7850 - val_loss: 0.4675 - val_accuracy: 0.8117\nEpoch 96/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4357 - accuracy: 0.7834 - val_loss: 0.4674 - val_accuracy: 0.8117\nEpoch 97/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4351 - accuracy: 0.7883 - val_loss: 0.4677 - val_accuracy: 0.8117\nEpoch 98/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4352 - accuracy: 0.7883 - val_loss: 0.4675 - val_accuracy: 0.8052\nEpoch 99/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4351 - accuracy: 0.7883 - val_loss: 0.4662 - val_accuracy: 0.8117\nEpoch 100/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4348 - accuracy: 0.7866 - val_loss: 0.4672 - val_accuracy: 0.8052\n","output_type":"stream"},{"execution_count":61,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.History at 0x7b1402352dd0>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Using Keras-Tuner to find best number of neurons in a particular layer","metadata":{}},{"cell_type":"code","source":"import keras_tuner as kt\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_model(hp):\n    model = Sequential()\n    units = hp.Int('random_units', min_value=4, max_value=128)\n    model.add(Dense(units=units, activation='relu', input_dim=6))\n    model.add(Dense(1, activation='sigmoid'))\n    model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n    return model\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-01-10T14:22:30.045743Z","iopub.execute_input":"2024-01-10T14:22:30.046814Z","iopub.status.idle":"2024-01-10T14:22:30.055562Z","shell.execute_reply.started":"2024-01-10T14:22:30.046773Z","shell.execute_reply":"2024-01-10T14:22:30.054005Z"},"trusted":true},"execution_count":95,"outputs":[]},{"cell_type":"code","source":"tuner = kt.RandomSearch(build_model, objective='val_accuracy', max_trials=15, directory='mydir',project_name='my_tuner')","metadata":{"execution":{"iopub.status.busy":"2024-01-10T14:24:04.527838Z","iopub.execute_input":"2024-01-10T14:24:04.529320Z","iopub.status.idle":"2024-01-10T14:24:04.546330Z","shell.execute_reply.started":"2024-01-10T14:24:04.529265Z","shell.execute_reply":"2024-01-10T14:24:04.545076Z"},"trusted":true},"execution_count":99,"outputs":[{"name":"stdout","text":"Reloading Tuner from mydir/my_tuner/tuner0.json\n","output_type":"stream"}]},{"cell_type":"code","source":"tuner.search(X_train,y_train,epochs=30,validation_data=(X_test,y_test))","metadata":{"execution":{"iopub.status.busy":"2024-01-10T14:24:21.543134Z","iopub.execute_input":"2024-01-10T14:24:21.544335Z","iopub.status.idle":"2024-01-10T14:24:41.929948Z","shell.execute_reply.started":"2024-01-10T14:24:21.544293Z","shell.execute_reply":"2024-01-10T14:24:41.928458Z"},"trusted":true},"execution_count":100,"outputs":[{"name":"stdout","text":"Trial 15 Complete [00h 00m 04s]\nval_accuracy: 0.8051947951316833\n\nBest val_accuracy So Far: 0.8181818127632141\nTotal elapsed time: 00h 06m 39s\n","output_type":"stream"}]},{"cell_type":"code","source":"tuner.get_best_hyperparameters()[0].values","metadata":{"execution":{"iopub.status.busy":"2024-01-10T14:24:48.350399Z","iopub.execute_input":"2024-01-10T14:24:48.350887Z","iopub.status.idle":"2024-01-10T14:24:48.359596Z","shell.execute_reply.started":"2024-01-10T14:24:48.350846Z","shell.execute_reply":"2024-01-10T14:24:48.358178Z"},"trusted":true},"execution_count":101,"outputs":[{"execution_count":101,"output_type":"execute_result","data":{"text/plain":"{'random_units': 128}"},"metadata":{}}]},{"cell_type":"code","source":"model = tuner.get_best_models(num_models=1)[0]","metadata":{"execution":{"iopub.status.busy":"2024-01-10T14:25:28.914107Z","iopub.execute_input":"2024-01-10T14:25:28.914618Z","iopub.status.idle":"2024-01-10T14:25:29.855618Z","shell.execute_reply.started":"2024-01-10T14:25:28.914578Z","shell.execute_reply":"2024-01-10T14:25:29.854274Z"},"trusted":true},"execution_count":102,"outputs":[]},{"cell_type":"code","source":"model.fit(X_train,y_train,batch_size=32,epochs=100,initial_epoch=6,validation_data=(X_test,y_test))","metadata":{"execution":{"iopub.status.busy":"2024-01-10T14:25:31.819457Z","iopub.execute_input":"2024-01-10T14:25:31.821314Z","iopub.status.idle":"2024-01-10T14:25:40.575225Z","shell.execute_reply.started":"2024-01-10T14:25:31.821254Z","shell.execute_reply":"2024-01-10T14:25:40.573854Z"},"trusted":true},"execution_count":103,"outputs":[{"name":"stdout","text":"Epoch 7/100\n20/20 [==============================] - 1s 13ms/step - loss: 0.4444 - accuracy: 0.7818 - val_loss: 0.4566 - val_accuracy: 0.8117\nEpoch 8/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4433 - accuracy: 0.7801 - val_loss: 0.4580 - val_accuracy: 0.8117\nEpoch 9/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4433 - accuracy: 0.7801 - val_loss: 0.4570 - val_accuracy: 0.8182\nEpoch 10/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4427 - accuracy: 0.7818 - val_loss: 0.4580 - val_accuracy: 0.8117\nEpoch 11/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4429 - accuracy: 0.7899 - val_loss: 0.4562 - val_accuracy: 0.8117\nEpoch 12/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4416 - accuracy: 0.7818 - val_loss: 0.4566 - val_accuracy: 0.8117\nEpoch 13/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4414 - accuracy: 0.7834 - val_loss: 0.4573 - val_accuracy: 0.8182\nEpoch 14/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4408 - accuracy: 0.7883 - val_loss: 0.4560 - val_accuracy: 0.8117\nEpoch 15/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4395 - accuracy: 0.7850 - val_loss: 0.4582 - val_accuracy: 0.8182\nEpoch 16/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4393 - accuracy: 0.7850 - val_loss: 0.4563 - val_accuracy: 0.8117\nEpoch 17/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4391 - accuracy: 0.7834 - val_loss: 0.4592 - val_accuracy: 0.8117\nEpoch 18/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4391 - accuracy: 0.7850 - val_loss: 0.4571 - val_accuracy: 0.8182\nEpoch 19/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4378 - accuracy: 0.7834 - val_loss: 0.4556 - val_accuracy: 0.8117\nEpoch 20/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4372 - accuracy: 0.7834 - val_loss: 0.4554 - val_accuracy: 0.8117\nEpoch 21/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4369 - accuracy: 0.7801 - val_loss: 0.4546 - val_accuracy: 0.8117\nEpoch 22/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4377 - accuracy: 0.7866 - val_loss: 0.4558 - val_accuracy: 0.8117\nEpoch 23/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4364 - accuracy: 0.7866 - val_loss: 0.4552 - val_accuracy: 0.8052\nEpoch 24/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4365 - accuracy: 0.7801 - val_loss: 0.4553 - val_accuracy: 0.8052\nEpoch 25/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4354 - accuracy: 0.7866 - val_loss: 0.4571 - val_accuracy: 0.8182\nEpoch 26/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4351 - accuracy: 0.7866 - val_loss: 0.4589 - val_accuracy: 0.8182\nEpoch 27/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4350 - accuracy: 0.7866 - val_loss: 0.4581 - val_accuracy: 0.8247\nEpoch 28/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4345 - accuracy: 0.7866 - val_loss: 0.4586 - val_accuracy: 0.8182\nEpoch 29/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4342 - accuracy: 0.7915 - val_loss: 0.4573 - val_accuracy: 0.8182\nEpoch 30/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.4341 - accuracy: 0.7834 - val_loss: 0.4577 - val_accuracy: 0.8312\nEpoch 31/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4331 - accuracy: 0.7834 - val_loss: 0.4578 - val_accuracy: 0.8182\nEpoch 32/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.4331 - accuracy: 0.7866 - val_loss: 0.4577 - val_accuracy: 0.8182\nEpoch 33/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4323 - accuracy: 0.7883 - val_loss: 0.4572 - val_accuracy: 0.8182\nEpoch 34/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4321 - accuracy: 0.7818 - val_loss: 0.4568 - val_accuracy: 0.8247\nEpoch 35/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4322 - accuracy: 0.7850 - val_loss: 0.4560 - val_accuracy: 0.8182\nEpoch 36/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4318 - accuracy: 0.7850 - val_loss: 0.4553 - val_accuracy: 0.8247\nEpoch 37/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4306 - accuracy: 0.7850 - val_loss: 0.4553 - val_accuracy: 0.8247\nEpoch 38/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.4302 - accuracy: 0.7899 - val_loss: 0.4572 - val_accuracy: 0.8247\nEpoch 39/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4301 - accuracy: 0.7834 - val_loss: 0.4567 - val_accuracy: 0.8247\nEpoch 40/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4297 - accuracy: 0.7883 - val_loss: 0.4552 - val_accuracy: 0.8247\nEpoch 41/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4295 - accuracy: 0.7932 - val_loss: 0.4561 - val_accuracy: 0.8312\nEpoch 42/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4291 - accuracy: 0.7883 - val_loss: 0.4560 - val_accuracy: 0.8247\nEpoch 43/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4292 - accuracy: 0.7866 - val_loss: 0.4559 - val_accuracy: 0.8247\nEpoch 44/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4287 - accuracy: 0.7883 - val_loss: 0.4558 - val_accuracy: 0.8182\nEpoch 45/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4280 - accuracy: 0.7915 - val_loss: 0.4563 - val_accuracy: 0.8182\nEpoch 46/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.7899 - val_loss: 0.4556 - val_accuracy: 0.8312\nEpoch 47/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4270 - accuracy: 0.7899 - val_loss: 0.4572 - val_accuracy: 0.8377\nEpoch 48/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4262 - accuracy: 0.7883 - val_loss: 0.4586 - val_accuracy: 0.8247\nEpoch 49/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.4259 - accuracy: 0.7866 - val_loss: 0.4583 - val_accuracy: 0.8312\nEpoch 50/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4264 - accuracy: 0.7915 - val_loss: 0.4565 - val_accuracy: 0.8312\nEpoch 51/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4258 - accuracy: 0.7899 - val_loss: 0.4546 - val_accuracy: 0.8247\nEpoch 52/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4252 - accuracy: 0.7964 - val_loss: 0.4571 - val_accuracy: 0.8377\nEpoch 53/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4246 - accuracy: 0.7915 - val_loss: 0.4564 - val_accuracy: 0.8312\nEpoch 54/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4249 - accuracy: 0.7948 - val_loss: 0.4565 - val_accuracy: 0.8312\nEpoch 55/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4242 - accuracy: 0.7932 - val_loss: 0.4584 - val_accuracy: 0.8312\nEpoch 56/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4246 - accuracy: 0.7932 - val_loss: 0.4578 - val_accuracy: 0.8312\nEpoch 57/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4236 - accuracy: 0.7932 - val_loss: 0.4584 - val_accuracy: 0.8247\nEpoch 58/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4231 - accuracy: 0.7899 - val_loss: 0.4595 - val_accuracy: 0.8182\nEpoch 59/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4233 - accuracy: 0.7964 - val_loss: 0.4585 - val_accuracy: 0.8377\nEpoch 60/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4230 - accuracy: 0.7932 - val_loss: 0.4577 - val_accuracy: 0.8247\nEpoch 61/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4233 - accuracy: 0.7980 - val_loss: 0.4567 - val_accuracy: 0.8312\nEpoch 62/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4226 - accuracy: 0.7915 - val_loss: 0.4599 - val_accuracy: 0.8247\nEpoch 63/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4217 - accuracy: 0.7932 - val_loss: 0.4602 - val_accuracy: 0.8312\nEpoch 64/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.4208 - accuracy: 0.7948 - val_loss: 0.4624 - val_accuracy: 0.8247\nEpoch 65/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4216 - accuracy: 0.7932 - val_loss: 0.4607 - val_accuracy: 0.8182\nEpoch 66/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4211 - accuracy: 0.7866 - val_loss: 0.4596 - val_accuracy: 0.8247\nEpoch 67/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4213 - accuracy: 0.7932 - val_loss: 0.4581 - val_accuracy: 0.8312\nEpoch 68/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4209 - accuracy: 0.7883 - val_loss: 0.4600 - val_accuracy: 0.8247\nEpoch 69/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4200 - accuracy: 0.7915 - val_loss: 0.4577 - val_accuracy: 0.8312\nEpoch 70/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4197 - accuracy: 0.7948 - val_loss: 0.4547 - val_accuracy: 0.8312\nEpoch 71/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4193 - accuracy: 0.7948 - val_loss: 0.4546 - val_accuracy: 0.8247\nEpoch 72/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4186 - accuracy: 0.7997 - val_loss: 0.4560 - val_accuracy: 0.8052\nEpoch 73/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4186 - accuracy: 0.7948 - val_loss: 0.4543 - val_accuracy: 0.8182\nEpoch 74/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4185 - accuracy: 0.7964 - val_loss: 0.4561 - val_accuracy: 0.8247\nEpoch 75/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4186 - accuracy: 0.7932 - val_loss: 0.4568 - val_accuracy: 0.8312\nEpoch 76/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4180 - accuracy: 0.7980 - val_loss: 0.4587 - val_accuracy: 0.8247\nEpoch 77/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4175 - accuracy: 0.8029 - val_loss: 0.4576 - val_accuracy: 0.8312\nEpoch 78/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4182 - accuracy: 0.8013 - val_loss: 0.4566 - val_accuracy: 0.8377\nEpoch 79/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4167 - accuracy: 0.7980 - val_loss: 0.4599 - val_accuracy: 0.8312\nEpoch 80/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4167 - accuracy: 0.7980 - val_loss: 0.4571 - val_accuracy: 0.8312\nEpoch 81/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4161 - accuracy: 0.7932 - val_loss: 0.4574 - val_accuracy: 0.8312\nEpoch 82/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4152 - accuracy: 0.7997 - val_loss: 0.4600 - val_accuracy: 0.8247\nEpoch 83/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4160 - accuracy: 0.7932 - val_loss: 0.4601 - val_accuracy: 0.8247\nEpoch 84/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4151 - accuracy: 0.7964 - val_loss: 0.4615 - val_accuracy: 0.8117\nEpoch 85/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4150 - accuracy: 0.7964 - val_loss: 0.4612 - val_accuracy: 0.8247\nEpoch 86/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4147 - accuracy: 0.8013 - val_loss: 0.4622 - val_accuracy: 0.8247\nEpoch 87/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4147 - accuracy: 0.8013 - val_loss: 0.4584 - val_accuracy: 0.8247\nEpoch 88/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4147 - accuracy: 0.7932 - val_loss: 0.4581 - val_accuracy: 0.8312\nEpoch 89/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4135 - accuracy: 0.7980 - val_loss: 0.4570 - val_accuracy: 0.8377\nEpoch 90/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4138 - accuracy: 0.8046 - val_loss: 0.4583 - val_accuracy: 0.8312\nEpoch 91/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4131 - accuracy: 0.7997 - val_loss: 0.4581 - val_accuracy: 0.8377\nEpoch 92/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4127 - accuracy: 0.7964 - val_loss: 0.4594 - val_accuracy: 0.8312\nEpoch 93/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4119 - accuracy: 0.8013 - val_loss: 0.4597 - val_accuracy: 0.8312\nEpoch 94/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4126 - accuracy: 0.7997 - val_loss: 0.4593 - val_accuracy: 0.8312\nEpoch 95/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4119 - accuracy: 0.8013 - val_loss: 0.4612 - val_accuracy: 0.8377\nEpoch 96/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4117 - accuracy: 0.7997 - val_loss: 0.4619 - val_accuracy: 0.8247\nEpoch 97/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4120 - accuracy: 0.7948 - val_loss: 0.4616 - val_accuracy: 0.8247\nEpoch 98/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4113 - accuracy: 0.8062 - val_loss: 0.4596 - val_accuracy: 0.8312\nEpoch 99/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4116 - accuracy: 0.8029 - val_loss: 0.4573 - val_accuracy: 0.8312\nEpoch 100/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8013 - val_loss: 0.4581 - val_accuracy: 0.8312\n","output_type":"stream"},{"execution_count":103,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.History at 0x7b1477b44190>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Finding appropiate number of layers using Keras-Tunner","metadata":{}},{"cell_type":"code","source":"def build_model(hp):\n    model= Sequential()\n    model.add(Dense(80,activation='relu',input_dim=6))\n    for i in range (hp.Int('num_layers',min_value=1,max_value=10)):\n        model.add(Dense(72,activation='relu'))\n    model.add(Dense(1,activation='sigmoid'))\n    model.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['accuracy'])\n    return model","metadata":{"execution":{"iopub.status.busy":"2024-01-10T14:36:28.187249Z","iopub.execute_input":"2024-01-10T14:36:28.187907Z","iopub.status.idle":"2024-01-10T14:36:28.199091Z","shell.execute_reply.started":"2024-01-10T14:36:28.187860Z","shell.execute_reply":"2024-01-10T14:36:28.197543Z"},"trusted":true},"execution_count":108,"outputs":[]},{"cell_type":"code","source":"tuner = kt.RandomSearch(build_model, objective='val_accuracy', max_trials=15, directory='mydir2',project_name='my_tuned_layers')","metadata":{"execution":{"iopub.status.busy":"2024-01-10T14:36:29.331144Z","iopub.execute_input":"2024-01-10T14:36:29.331879Z","iopub.status.idle":"2024-01-10T14:36:29.405293Z","shell.execute_reply.started":"2024-01-10T14:36:29.331841Z","shell.execute_reply":"2024-01-10T14:36:29.403819Z"},"trusted":true},"execution_count":109,"outputs":[]},{"cell_type":"code","source":"tuner.search(X_train,y_train,epochs=30,validation_data=(X_test,y_test))","metadata":{"execution":{"iopub.status.busy":"2024-01-10T14:36:47.339966Z","iopub.execute_input":"2024-01-10T14:36:47.340851Z","iopub.status.idle":"2024-01-10T14:37:49.713464Z","shell.execute_reply.started":"2024-01-10T14:36:47.340807Z","shell.execute_reply":"2024-01-10T14:37:49.711909Z"},"trusted":true},"execution_count":110,"outputs":[{"name":"stdout","text":"Trial 10 Complete [00h 00m 06s]\nval_accuracy: 0.8116883039474487\n\nBest val_accuracy So Far: 0.8311688303947449\nTotal elapsed time: 00h 01m 02s\n","output_type":"stream"}]},{"cell_type":"code","source":"tuner.get_best_hyperparameters()[0].values","metadata":{"execution":{"iopub.status.busy":"2024-01-10T14:38:04.421097Z","iopub.execute_input":"2024-01-10T14:38:04.421633Z","iopub.status.idle":"2024-01-10T14:38:04.432000Z","shell.execute_reply.started":"2024-01-10T14:38:04.421596Z","shell.execute_reply":"2024-01-10T14:38:04.430377Z"},"trusted":true},"execution_count":111,"outputs":[{"execution_count":111,"output_type":"execute_result","data":{"text/plain":"{'num_layers': 4}"},"metadata":{}}]},{"cell_type":"code","source":"model = tuner.get_best_models(num_models=1)[0]","metadata":{"execution":{"iopub.status.busy":"2024-01-10T14:38:22.461117Z","iopub.execute_input":"2024-01-10T14:38:22.462512Z","iopub.status.idle":"2024-01-10T14:38:23.563284Z","shell.execute_reply.started":"2024-01-10T14:38:22.462465Z","shell.execute_reply":"2024-01-10T14:38:23.561974Z"},"trusted":true},"execution_count":112,"outputs":[]},{"cell_type":"code","source":"model.fit(X_train,y_train,batch_size=32,epochs=100,initial_epoch=6,validation_data=(X_test,y_test))","metadata":{"execution":{"iopub.status.busy":"2024-01-10T14:38:40.225994Z","iopub.execute_input":"2024-01-10T14:38:40.226526Z","iopub.status.idle":"2024-01-10T14:38:50.980435Z","shell.execute_reply.started":"2024-01-10T14:38:40.226486Z","shell.execute_reply":"2024-01-10T14:38:50.979073Z"},"trusted":true},"execution_count":113,"outputs":[{"name":"stdout","text":"Epoch 7/100\n20/20 [==============================] - 1s 17ms/step - loss: 0.4190 - accuracy: 0.7850 - val_loss: 0.4733 - val_accuracy: 0.8247\nEpoch 8/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.4176 - accuracy: 0.7915 - val_loss: 0.4883 - val_accuracy: 0.8052\nEpoch 9/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.4124 - accuracy: 0.7964 - val_loss: 0.4814 - val_accuracy: 0.7922\nEpoch 10/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.4114 - accuracy: 0.7850 - val_loss: 0.4722 - val_accuracy: 0.8377\nEpoch 11/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.4023 - accuracy: 0.8046 - val_loss: 0.4859 - val_accuracy: 0.8117\nEpoch 12/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.3980 - accuracy: 0.7997 - val_loss: 0.4998 - val_accuracy: 0.8052\nEpoch 13/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.3908 - accuracy: 0.8094 - val_loss: 0.5114 - val_accuracy: 0.8052\nEpoch 14/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.3978 - accuracy: 0.8094 - val_loss: 0.5209 - val_accuracy: 0.8182\nEpoch 15/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.3799 - accuracy: 0.8257 - val_loss: 0.5203 - val_accuracy: 0.8052\nEpoch 16/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.3770 - accuracy: 0.8225 - val_loss: 0.5189 - val_accuracy: 0.7532\nEpoch 17/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.3785 - accuracy: 0.8339 - val_loss: 0.5261 - val_accuracy: 0.8117\nEpoch 18/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.3638 - accuracy: 0.8257 - val_loss: 0.4915 - val_accuracy: 0.8117\nEpoch 19/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.3651 - accuracy: 0.8355 - val_loss: 0.5173 - val_accuracy: 0.7987\nEpoch 20/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.3526 - accuracy: 0.8453 - val_loss: 0.5667 - val_accuracy: 0.7143\nEpoch 21/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.3544 - accuracy: 0.8290 - val_loss: 0.5305 - val_accuracy: 0.7468\nEpoch 22/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.3470 - accuracy: 0.8306 - val_loss: 0.5129 - val_accuracy: 0.7857\nEpoch 23/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.3328 - accuracy: 0.8583 - val_loss: 0.5877 - val_accuracy: 0.7532\nEpoch 24/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.3374 - accuracy: 0.8502 - val_loss: 0.5431 - val_accuracy: 0.7857\nEpoch 25/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.3230 - accuracy: 0.8648 - val_loss: 0.5437 - val_accuracy: 0.7922\nEpoch 26/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.3181 - accuracy: 0.8583 - val_loss: 0.5680 - val_accuracy: 0.7597\nEpoch 27/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.3145 - accuracy: 0.8583 - val_loss: 0.5594 - val_accuracy: 0.7597\nEpoch 28/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.3157 - accuracy: 0.8664 - val_loss: 0.5483 - val_accuracy: 0.7792\nEpoch 29/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.2931 - accuracy: 0.8730 - val_loss: 0.5806 - val_accuracy: 0.7273\nEpoch 30/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.2907 - accuracy: 0.8827 - val_loss: 0.7294 - val_accuracy: 0.7597\nEpoch 31/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.2889 - accuracy: 0.8779 - val_loss: 0.6780 - val_accuracy: 0.7662\nEpoch 32/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.2760 - accuracy: 0.8974 - val_loss: 0.7450 - val_accuracy: 0.7662\nEpoch 33/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.2629 - accuracy: 0.8958 - val_loss: 0.6006 - val_accuracy: 0.7727\nEpoch 34/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.2613 - accuracy: 0.8876 - val_loss: 0.7299 - val_accuracy: 0.7922\nEpoch 35/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.2715 - accuracy: 0.8811 - val_loss: 0.6193 - val_accuracy: 0.7597\nEpoch 36/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.2464 - accuracy: 0.9007 - val_loss: 0.6239 - val_accuracy: 0.7857\nEpoch 37/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.2365 - accuracy: 0.8990 - val_loss: 0.7184 - val_accuracy: 0.6883\nEpoch 38/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.2455 - accuracy: 0.8974 - val_loss: 0.6720 - val_accuracy: 0.7857\nEpoch 39/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.2394 - accuracy: 0.9023 - val_loss: 0.7066 - val_accuracy: 0.7662\nEpoch 40/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.2192 - accuracy: 0.9039 - val_loss: 0.7359 - val_accuracy: 0.7273\nEpoch 41/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.2114 - accuracy: 0.9137 - val_loss: 1.0147 - val_accuracy: 0.7338\nEpoch 42/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.2144 - accuracy: 0.9055 - val_loss: 0.8352 - val_accuracy: 0.7987\nEpoch 43/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.1885 - accuracy: 0.9153 - val_loss: 0.7448 - val_accuracy: 0.7468\nEpoch 44/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.2140 - accuracy: 0.9153 - val_loss: 0.9534 - val_accuracy: 0.7597\nEpoch 45/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.1873 - accuracy: 0.9283 - val_loss: 0.8896 - val_accuracy: 0.7857\nEpoch 46/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.1873 - accuracy: 0.9218 - val_loss: 1.0699 - val_accuracy: 0.7403\nEpoch 47/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.1698 - accuracy: 0.9349 - val_loss: 1.0969 - val_accuracy: 0.7532\nEpoch 48/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.1745 - accuracy: 0.9300 - val_loss: 0.7315 - val_accuracy: 0.6688\nEpoch 49/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.1640 - accuracy: 0.9316 - val_loss: 0.9688 - val_accuracy: 0.7922\nEpoch 50/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.1947 - accuracy: 0.9104 - val_loss: 0.9006 - val_accuracy: 0.7727\nEpoch 51/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.1437 - accuracy: 0.9414 - val_loss: 1.0253 - val_accuracy: 0.6948\nEpoch 52/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.1614 - accuracy: 0.9381 - val_loss: 1.0890 - val_accuracy: 0.7857\nEpoch 53/100\n20/20 [==============================] - 0s 6ms/step - loss: 0.1492 - accuracy: 0.9349 - val_loss: 0.9913 - val_accuracy: 0.7727\nEpoch 54/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.1490 - accuracy: 0.9414 - val_loss: 1.0624 - val_accuracy: 0.7922\nEpoch 55/100\n20/20 [==============================] - 0s 6ms/step - loss: 0.1411 - accuracy: 0.9349 - val_loss: 0.8848 - val_accuracy: 0.7143\nEpoch 56/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.1587 - accuracy: 0.9365 - val_loss: 1.1865 - val_accuracy: 0.7273\nEpoch 57/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.1390 - accuracy: 0.9463 - val_loss: 1.2293 - val_accuracy: 0.7727\nEpoch 58/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.1371 - accuracy: 0.9495 - val_loss: 1.0479 - val_accuracy: 0.7792\nEpoch 59/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.1166 - accuracy: 0.9577 - val_loss: 1.6608 - val_accuracy: 0.7403\nEpoch 60/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.1319 - accuracy: 0.9511 - val_loss: 1.0895 - val_accuracy: 0.7857\nEpoch 61/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.1504 - accuracy: 0.9414 - val_loss: 1.0515 - val_accuracy: 0.7468\nEpoch 62/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.1022 - accuracy: 0.9560 - val_loss: 1.2475 - val_accuracy: 0.6948\nEpoch 63/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.1195 - accuracy: 0.9593 - val_loss: 1.1054 - val_accuracy: 0.7662\nEpoch 64/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.0927 - accuracy: 0.9707 - val_loss: 1.0392 - val_accuracy: 0.7597\nEpoch 65/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.1085 - accuracy: 0.9560 - val_loss: 1.1045 - val_accuracy: 0.7792\nEpoch 66/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.1282 - accuracy: 0.9544 - val_loss: 1.2647 - val_accuracy: 0.7727\nEpoch 67/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.1002 - accuracy: 0.9691 - val_loss: 1.1245 - val_accuracy: 0.7662\nEpoch 68/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.0973 - accuracy: 0.9544 - val_loss: 1.2755 - val_accuracy: 0.7727\nEpoch 69/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.0782 - accuracy: 0.9707 - val_loss: 1.2531 - val_accuracy: 0.7922\nEpoch 70/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.1023 - accuracy: 0.9609 - val_loss: 1.2141 - val_accuracy: 0.7857\nEpoch 71/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.0768 - accuracy: 0.9674 - val_loss: 1.1993 - val_accuracy: 0.7597\nEpoch 72/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.1208 - accuracy: 0.9560 - val_loss: 1.2241 - val_accuracy: 0.7532\nEpoch 73/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.0581 - accuracy: 0.9821 - val_loss: 1.5364 - val_accuracy: 0.7662\nEpoch 74/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.0745 - accuracy: 0.9707 - val_loss: 1.4054 - val_accuracy: 0.7597\nEpoch 75/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.0975 - accuracy: 0.9609 - val_loss: 1.2407 - val_accuracy: 0.7532\nEpoch 76/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.0868 - accuracy: 0.9707 - val_loss: 1.3949 - val_accuracy: 0.7857\nEpoch 77/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.0868 - accuracy: 0.9707 - val_loss: 1.3575 - val_accuracy: 0.7532\nEpoch 78/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.0700 - accuracy: 0.9707 - val_loss: 1.3538 - val_accuracy: 0.7597\nEpoch 79/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.0421 - accuracy: 0.9935 - val_loss: 1.8764 - val_accuracy: 0.7468\nEpoch 80/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.0697 - accuracy: 0.9723 - val_loss: 1.3413 - val_accuracy: 0.7338\nEpoch 81/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.0858 - accuracy: 0.9707 - val_loss: 1.5256 - val_accuracy: 0.7727\nEpoch 82/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.0555 - accuracy: 0.9805 - val_loss: 1.5403 - val_accuracy: 0.7727\nEpoch 83/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.1037 - accuracy: 0.9593 - val_loss: 1.5029 - val_accuracy: 0.7597\nEpoch 84/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.0401 - accuracy: 0.9902 - val_loss: 1.3420 - val_accuracy: 0.7727\nEpoch 85/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.0514 - accuracy: 0.9837 - val_loss: 1.5197 - val_accuracy: 0.7532\nEpoch 86/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.0422 - accuracy: 0.9837 - val_loss: 1.6526 - val_accuracy: 0.7208\nEpoch 87/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.0980 - accuracy: 0.9674 - val_loss: 1.4808 - val_accuracy: 0.7662\nEpoch 88/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.0496 - accuracy: 0.9788 - val_loss: 1.6066 - val_accuracy: 0.7338\nEpoch 89/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.0461 - accuracy: 0.9853 - val_loss: 1.6633 - val_accuracy: 0.7403\nEpoch 90/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.0470 - accuracy: 0.9853 - val_loss: 1.8773 - val_accuracy: 0.7662\nEpoch 91/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.0421 - accuracy: 0.9870 - val_loss: 2.1905 - val_accuracy: 0.7403\nEpoch 92/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.0421 - accuracy: 0.9919 - val_loss: 1.7274 - val_accuracy: 0.7403\nEpoch 93/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.0841 - accuracy: 0.9723 - val_loss: 2.0095 - val_accuracy: 0.7662\nEpoch 94/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.0432 - accuracy: 0.9886 - val_loss: 1.7377 - val_accuracy: 0.7532\nEpoch 95/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.0354 - accuracy: 0.9919 - val_loss: 1.8574 - val_accuracy: 0.7468\nEpoch 96/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.0695 - accuracy: 0.9756 - val_loss: 1.6798 - val_accuracy: 0.7662\nEpoch 97/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.0818 - accuracy: 0.9707 - val_loss: 1.7714 - val_accuracy: 0.7532\nEpoch 98/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.0244 - accuracy: 0.9919 - val_loss: 1.7187 - val_accuracy: 0.7532\nEpoch 99/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.0445 - accuracy: 0.9870 - val_loss: 1.8670 - val_accuracy: 0.7468\nEpoch 100/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.0198 - accuracy: 0.9951 - val_loss: 1.8348 - val_accuracy: 0.7727\n","output_type":"stream"},{"execution_count":113,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.History at 0x7b1403282500>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}